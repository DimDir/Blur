{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# get all files' names in derictory\n",
    "os.chdir(\"D:\\Data\\Blurring\\clean\")\n",
    "clean_name = []\n",
    "for root, dirs, files in os.walk(\".\", topdown=False):\n",
    "    for name in files:\n",
    "        clean_name.append(name)\n",
    "\n",
    "os.chdir(\"D:\\Data\\Blurring\\\\blur\")\n",
    "blur_name = []\n",
    "for root, dirs, files in os.walk(\".\", topdown=False):\n",
    "    for name in files:\n",
    "        blur_name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = np.zeros(shape=(1, 481, 720, 3))\n",
    "\n",
    "for name in clean_name:\n",
    "    img_new = Image.open(\"D:\\Data\\Blurring\\clean/\" + name)\n",
    "    arr_new = np.asarray(img_new, dtype='uint8')\n",
    "    X_clean = np.append(X_clean, arr_new[np.newaxis,:], axis=0)\n",
    "    \n",
    "X_blur = np.zeros(shape=(1, 481, 720, 3))\n",
    "\n",
    "for name in blur_name:\n",
    "    img_new = Image.open(\"D:\\Data\\Blurring\\\\blur/\" + name)\n",
    "    arr_new = np.asarray(img_new, dtype='uint8')\n",
    "    X_blur = np.append(X_blur, arr_new[np.newaxis,:], axis=0)\n",
    "    \n",
    "del clean_name, blur_name, arr_new\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 481, 720, 3), (125, 481, 720, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.shape, X_blur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 481, 720, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = X_clean[1:]\n",
    "X_blur = X_blur[1:]\n",
    "X_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X_clean, X_blur), axis=0)\n",
    "\n",
    "del X_clean, X_blur \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248, 481, 720, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor(X)\n",
    "X = X / 255\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248, 3, 481, 720])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.permute(0, 3, 1, 2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([248, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = torch.ones((124,1)), torch.zeros((124, 1))\n",
    "y = torch.cat((a,b))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.numpy(), \\\n",
    "                                                    y.numpy(), \\\n",
    "                                                    shuffle=True,\\\n",
    "                                                    test_size=.1)\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([223, 3, 481, 720])\n",
      "torch.Size([25, 3, 481, 720])\n",
      "torch.Size([223, 1])\n",
      "torch.Size([25, 1])\n"
     ]
    }
   ],
   "source": [
    "def shapes(lists):\n",
    "    for el in lists:\n",
    "        print(el.shape)\n",
    "        \n",
    "shapes([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X, y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlurNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(3, 3))\n",
       "  (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool4): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (fc1): Linear(in_features=792, out_features=140, bias=True)\n",
       "  (fc2): Linear(in_features=140, out_features=40, bias=True)\n",
       "  (fc3): Linear(in_features=40, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BlurNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BlurNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=3)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, padding=0)\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=16, out_channels=8, kernel_size=5, padding=0)\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.conv5 = torch.nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, padding=0)\n",
    "        self.pool5 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(4 * 11 * 18, 140)\n",
    "        self.fc2 = torch.nn.Linear(140, 40)\n",
    "        self.fc3 = torch.nn.Linear(40, 1)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool3(self.relu(self.conv3(x)))\n",
    "        x = self.pool4(self.relu(self.conv4(x)))\n",
    "        x = self.pool5(self.relu(self.conv5(x)))\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x     \n",
    "    \n",
    "blurnet = BlurNet()\n",
    "blurnet.to('cuda: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(blurnet.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to('cuda: 0')\n",
    "y_train = y_train.to('cuda: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 OK.\n",
      "Epoch 1 OK.\n",
      "Epoch 2 OK.\n",
      "Epoch 3 OK.\n",
      "Epoch 4 OK.\n",
      "Epoch 5 OK.\n",
      "Epoch 6 OK.\n",
      "Epoch 7 OK.\n",
      "Epoch 8 OK.\n",
      "Epoch 9 OK.\n",
      "Epoch 10 OK.\n",
      "Epoch 11 OK.\n",
      "Epoch 12 OK.\n",
      "Epoch 13 OK.\n",
      "Epoch 14 OK.\n",
      "Epoch 15 OK.\n",
      "Epoch 16 OK.\n",
      "Epoch 17 OK.\n",
      "Epoch 18 OK.\n",
      "Epoch 19 OK.\n",
      "Epoch 20 OK.\n",
      "Epoch 21 OK.\n",
      "Epoch 22 OK.\n",
      "Epoch 23 OK.\n",
      "Epoch 24 OK.\n",
      "Epoch 25 OK.\n",
      "Epoch 26 OK.\n",
      "Epoch 27 OK.\n",
      "Epoch 28 OK.\n",
      "Epoch 29 OK.\n",
      "Epoch 30 OK.\n",
      "Epoch 31 OK.\n",
      "Epoch 32 OK.\n",
      "Epoch 33 OK.\n",
      "Epoch 34 OK.\n",
      "Epoch 35 OK.\n",
      "Epoch 36 OK.\n",
      "Epoch 37 OK.\n",
      "Epoch 38 OK.\n",
      "Epoch 39 OK.\n",
      "Epoch 40 OK.\n",
      "Epoch 41 OK.\n",
      "Epoch 42 OK.\n",
      "Epoch 43 OK.\n",
      "Epoch 44 OK.\n",
      "Epoch 45 OK.\n",
      "Epoch 46 OK.\n",
      "Epoch 47 OK.\n",
      "Epoch 48 OK.\n",
      "Epoch 49 OK.\n",
      "Epoch 50 OK.\n",
      "Epoch 51 OK.\n",
      "Epoch 52 OK.\n",
      "Epoch 53 OK.\n",
      "Epoch 54 OK.\n",
      "Epoch 55 OK.\n",
      "Epoch 56 OK.\n",
      "Epoch 57 OK.\n",
      "Epoch 58 OK.\n",
      "Epoch 59 OK.\n",
      "Epoch 60 OK.\n",
      "Epoch 61 OK.\n",
      "Epoch 62 OK.\n",
      "Epoch 63 OK.\n",
      "Epoch 64 OK.\n",
      "Epoch 65 OK.\n",
      "Epoch 66 OK.\n",
      "Epoch 67 OK.\n",
      "Epoch 68 OK.\n",
      "Epoch 69 OK.\n",
      "Epoch 70 OK.\n",
      "Epoch 71 OK.\n",
      "Epoch 72 OK.\n",
      "Epoch 73 OK.\n",
      "Epoch 74 OK.\n",
      "Epoch 75 OK.\n",
      "Epoch 76 OK.\n",
      "Epoch 77 OK.\n",
      "Epoch 78 OK.\n",
      "Epoch 79 OK.\n",
      "Epoch 80 OK.\n",
      "Epoch 81 OK.\n",
      "Epoch 82 OK.\n",
      "Epoch 83 OK.\n",
      "Epoch 84 OK.\n",
      "Epoch 85 OK.\n",
      "Epoch 86 OK.\n",
      "Epoch 87 OK.\n",
      "Epoch 88 OK.\n",
      "Epoch 89 OK.\n",
      "Epoch 90 OK.\n",
      "Epoch 91 OK.\n",
      "Epoch 92 OK.\n",
      "Epoch 93 OK.\n",
      "Epoch 94 OK.\n",
      "Epoch 95 OK.\n",
      "Epoch 96 OK.\n",
      "Epoch 97 OK.\n",
      "Epoch 98 OK.\n",
      "Epoch 99 OK.\n",
      "Epoch 100 OK.\n",
      "Epoch 101 OK.\n",
      "Epoch 102 OK.\n",
      "Epoch 103 OK.\n",
      "Epoch 104 OK.\n",
      "Epoch 105 OK.\n",
      "Epoch 106 OK.\n",
      "Epoch 107 OK.\n",
      "Epoch 108 OK.\n",
      "Epoch 109 OK.\n",
      "Epoch 110 OK.\n",
      "Epoch 111 OK.\n",
      "Epoch 112 OK.\n",
      "Epoch 113 OK.\n",
      "Epoch 114 OK.\n",
      "Epoch 115 OK.\n",
      "Epoch 116 OK.\n",
      "Epoch 117 OK.\n",
      "Epoch 118 OK.\n",
      "Epoch 119 OK.\n",
      "Epoch 120 OK.\n",
      "Epoch 121 OK.\n",
      "Epoch 122 OK.\n",
      "Epoch 123 OK.\n",
      "Epoch 124 OK.\n",
      "Epoch 125 OK.\n",
      "Epoch 126 OK.\n",
      "Epoch 127 OK.\n",
      "Epoch 128 OK.\n",
      "Epoch 129 OK.\n",
      "Epoch 130 OK.\n",
      "Epoch 131 OK.\n",
      "Epoch 132 OK.\n",
      "Epoch 133 OK.\n",
      "Epoch 134 OK.\n",
      "Epoch 135 OK.\n",
      "Epoch 136 OK.\n",
      "Epoch 137 OK.\n",
      "Epoch 138 OK.\n",
      "Epoch 139 OK.\n",
      "Epoch 140 OK.\n",
      "Epoch 141 OK.\n",
      "Epoch 142 OK.\n",
      "Epoch 143 OK.\n",
      "Epoch 144 OK.\n",
      "Epoch 145 OK.\n",
      "Epoch 146 OK.\n",
      "Epoch 147 OK.\n",
      "Epoch 148 OK.\n",
      "Epoch 149 OK.\n",
      "Epoch 150 OK.\n",
      "Epoch 151 OK.\n",
      "Epoch 152 OK.\n",
      "Epoch 153 OK.\n",
      "Epoch 154 OK.\n",
      "Epoch 155 OK.\n",
      "Epoch 156 OK.\n",
      "Epoch 157 OK.\n",
      "Epoch 158 OK.\n",
      "Epoch 159 OK.\n",
      "Epoch 160 OK.\n",
      "Epoch 161 OK.\n",
      "Epoch 162 OK.\n",
      "Epoch 163 OK.\n",
      "Epoch 164 OK.\n",
      "Epoch 165 OK.\n",
      "Epoch 166 OK.\n",
      "Epoch 167 OK.\n",
      "Epoch 168 OK.\n",
      "Epoch 169 OK.\n",
      "Epoch 170 OK.\n",
      "Epoch 171 OK.\n",
      "Epoch 172 OK.\n",
      "Epoch 173 OK.\n",
      "Epoch 174 OK.\n",
      "Epoch 175 OK.\n",
      "Epoch 176 OK.\n",
      "Epoch 177 OK.\n",
      "Epoch 178 OK.\n",
      "Epoch 179 OK.\n",
      "Epoch 180 OK.\n",
      "Epoch 181 OK.\n",
      "Epoch 182 OK.\n",
      "Epoch 183 OK.\n",
      "Epoch 184 OK.\n",
      "Epoch 185 OK.\n",
      "Epoch 186 OK.\n",
      "Epoch 187 OK.\n",
      "Epoch 188 OK.\n",
      "Epoch 189 OK.\n",
      "Epoch 190 OK.\n",
      "Epoch 191 OK.\n",
      "Epoch 192 OK.\n",
      "Epoch 193 OK.\n",
      "Epoch 194 OK.\n",
      "Epoch 195 OK.\n",
      "Epoch 196 OK.\n",
      "Epoch 197 OK.\n",
      "Epoch 198 OK.\n",
      "Epoch 199 OK.\n",
      "Epoch 200 OK.\n",
      "Epoch 201 OK.\n",
      "Epoch 202 OK.\n",
      "Epoch 203 OK.\n",
      "Epoch 204 OK.\n",
      "Epoch 205 OK.\n",
      "Epoch 206 OK.\n",
      "Epoch 207 OK.\n",
      "Epoch 208 OK.\n",
      "Epoch 209 OK.\n",
      "Epoch 210 OK.\n",
      "Epoch 211 OK.\n",
      "Epoch 212 OK.\n",
      "Epoch 213 OK.\n",
      "Epoch 214 OK.\n",
      "Epoch 215 OK.\n",
      "Epoch 216 OK.\n",
      "Epoch 217 OK.\n",
      "Epoch 218 OK.\n",
      "Epoch 219 OK.\n",
      "Epoch 220 OK.\n",
      "Epoch 221 OK.\n",
      "Epoch 222 OK.\n",
      "Epoch 223 OK.\n",
      "Epoch 224 OK.\n",
      "Epoch 225 OK.\n",
      "Epoch 226 OK.\n",
      "Epoch 227 OK.\n",
      "Epoch 228 OK.\n",
      "Epoch 229 OK.\n",
      "Epoch 230 OK.\n",
      "Epoch 231 OK.\n",
      "Epoch 232 OK.\n",
      "Epoch 233 OK.\n",
      "Epoch 234 OK.\n",
      "Epoch 235 OK.\n",
      "Epoch 236 OK.\n",
      "Epoch 237 OK.\n",
      "Epoch 238 OK.\n",
      "Epoch 239 OK.\n",
      "Epoch 240 OK.\n",
      "Epoch 241 OK.\n",
      "Epoch 242 OK.\n",
      "Epoch 243 OK.\n",
      "Epoch 244 OK.\n",
      "Epoch 245 OK.\n",
      "Epoch 246 OK.\n",
      "Epoch 247 OK.\n",
      "Epoch 248 OK.\n",
      "Epoch 249 OK.\n",
      "Epoch 250 OK.\n",
      "Epoch 251 OK.\n",
      "Epoch 252 OK.\n",
      "Epoch 253 OK.\n",
      "Epoch 254 OK.\n",
      "Epoch 255 OK.\n",
      "Epoch 256 OK.\n",
      "Epoch 257 OK.\n",
      "Epoch 258 OK.\n",
      "Epoch 259 OK.\n",
      "Epoch 260 OK.\n",
      "Epoch 261 OK.\n",
      "Epoch 262 OK.\n",
      "Epoch 263 OK.\n",
      "Epoch 264 OK.\n",
      "Epoch 265 OK.\n",
      "Epoch 266 OK.\n",
      "Epoch 267 OK.\n",
      "Epoch 268 OK.\n",
      "Epoch 269 OK.\n",
      "Epoch 270 OK.\n",
      "Epoch 271 OK.\n",
      "Epoch 272 OK.\n",
      "Epoch 273 OK.\n",
      "Epoch 274 OK.\n",
      "Epoch 275 OK.\n",
      "Epoch 276 OK.\n",
      "Epoch 277 OK.\n",
      "Epoch 278 OK.\n",
      "Epoch 279 OK.\n",
      "Epoch 280 OK.\n",
      "Epoch 281 OK.\n",
      "Epoch 282 OK.\n",
      "Epoch 283 OK.\n",
      "Epoch 284 OK.\n",
      "Epoch 285 OK.\n",
      "Epoch 286 OK.\n",
      "Epoch 287 OK.\n",
      "Epoch 288 OK.\n",
      "Epoch 289 OK.\n",
      "Epoch 290 OK.\n",
      "Epoch 291 OK.\n",
      "Epoch 292 OK.\n",
      "Epoch 293 OK.\n",
      "Epoch 294 OK.\n",
      "Epoch 295 OK.\n",
      "Epoch 296 OK.\n",
      "Epoch 297 OK.\n",
      "Epoch 298 OK.\n",
      "Epoch 299 OK.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 31\n",
    "\n",
    "for epoch in range(300):\n",
    "    order = np.random.permutation(len(X_train))\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch_indexes = order[start_index: start_index + batch_size]\n",
    "        X_batch = X_train[batch_indexes].to('cuda: 0', dtype=torch.float)\n",
    "        y_batch = y_train[batch_indexes].to('cuda: 0', dtype=torch.float)\n",
    "        \n",
    "        y_pred = blurnet.forward(X_batch.float())\n",
    "\n",
    "        loss_val = loss(y_pred, y_batch)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch {} OK.\".format(epoch))\n",
    "    #blurnet.forward(X_train[1].float())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = blurnet.forward(X_test.float().to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1.])\n",
      "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
      "        0., 1., 0., 0., 0., 1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_test.flatten().data)\n",
    "print(predict.round().flatten().data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 1., 1.], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to('cuda: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6554e-09],\n",
       "        [4.8532e-10],\n",
       "        [1.0027e-10],\n",
       "        [6.0226e-10],\n",
       "        [4.3265e-08],\n",
       "        [4.9694e-10],\n",
       "        [8.4256e-11],\n",
       "        [9.5629e-10],\n",
       "        [4.3636e-10],\n",
       "        [2.1928e-10],\n",
       "        [1.0027e-10],\n",
       "        [2.5523e-10],\n",
       "        [8.4256e-11],\n",
       "        [6.7618e-09],\n",
       "        [5.5146e-10],\n",
       "        [2.3288e-10],\n",
       "        [1.0027e-10],\n",
       "        [1.0267e-10],\n",
       "        [5.5948e-10],\n",
       "        [1.4496e-10],\n",
       "        [3.6148e-10],\n",
       "        [7.9903e-08],\n",
       "        [3.0536e-10],\n",
       "        [8.4256e-11],\n",
       "        [2.2204e-10]], device='cuda:0', grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predict - y_test) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
